{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "thorough-dictionary",
      "metadata": {
        "id": "thorough-dictionary"
      },
      "source": [
        "## This retrieves all metadata including for fully embargoed items in all accounts\n",
        "For demonstration only and would need slight tweaking to give you exactly the metadata you want.\n",
        "This does not retrieve metadata for collections or projects.\n",
        "\n",
        "The end result is a spreadsheet of metadata with several things added or modified:\n",
        "1. The item owners name and email is added\n",
        "2. The group the item belongs to is added\n",
        "3. The author names are formatted to be more readable and ORCID is included\n",
        "4. The dates are split out into their own columns\n",
        "5. Any custom fields are separated out into their own columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pressed-williams",
      "metadata": {
        "id": "pressed-williams"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f7e37a43",
      "metadata": {
        "id": "f7e37a43"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import csv\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "authentic-lending",
      "metadata": {
        "id": "authentic-lending"
      },
      "source": [
        "## Set token, admin id, and base URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "continued-screen",
      "metadata": {
        "id": "continued-screen"
      },
      "outputs": [],
      "source": [
        "#Set the token in the header.\n",
        "api_call_headers = {'Authorization': '472a377327b51cfae63886af7744cea0886c366d2c1da513985355f54b4aa77b8b3b900706314ccad9d53b0c3fe10533a8a0dcd3375f39f25a21c04faa23e588'} #example: {'Authorization': 'token dkd8rskjdkfiwi49hgkw...'}\n",
        "\n",
        "#Set the base URL\n",
        "BASE_URL = 'https://api.figshare.com/v2'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "genuine-blowing",
      "metadata": {
        "id": "genuine-blowing"
      },
      "source": [
        "## Retrieve Metadata\n",
        "1. Get a list of basic metadata for all private records\n",
        "2. Select only published records (includes embargoed records)\n",
        "3. For each record get the full metadata and add in the owner name and email  \n",
        "4. Format dates\n",
        "5. Add in the name of the Group the record is part of\n",
        "6. Split out the custom metadata\n",
        "7. Save the dataframe to CSV or Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "impressed-guarantee",
      "metadata": {
        "id": "impressed-guarantee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gathered 18 private records\n"
          ]
        }
      ],
      "source": [
        "#Gather all private records (make sure your token is for a top level admin account)\n",
        "private_records = []\n",
        "for i in range(1,10):\n",
        "    records = json.loads(requests.get(BASE_URL + '/account/institution/articles?page_size=1000&page={}'.format(i), headers=api_call_headers).content)\n",
        "    private_records.extend(records)\n",
        "\n",
        "print('Gathered',len(private_records),'private records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0dd08bf8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'code'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "private_records[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "internal-coffee",
      "metadata": {
        "id": "internal-coffee"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "string indices must be integers, not 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m published_records \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m private_records:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublished_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m#if a record has a published date\u001b[39;00m\n\u001b[0;32m      5\u001b[0m            published_records\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(published_records), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords kept,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(private_records) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(published_records),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords removed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
          ]
        }
      ],
      "source": [
        "#Keep records that are either public or fully embargoed\n",
        "published_records = []\n",
        "for item in private_records:\n",
        "    if item['published_date'] != None: #if a record has a published date\n",
        "           published_records.append(item)\n",
        "\n",
        "print(len(published_records), \"records kept,\",len(private_records) - len(published_records),\"records removed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-official",
      "metadata": {
        "id": "involved-official"
      },
      "source": [
        "## Collect full metadata\n",
        "Using the list you have of basic metadata with owner id and owner name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miniature-process",
      "metadata": {
        "id": "miniature-process"
      },
      "outputs": [],
      "source": [
        "#For each id in the list, retrieve all the metadata for the article by visiting the Figshare article API endpoint\n",
        "#Admin token does not need to impersonate\n",
        "#This may take a while if there are a lot of items. ~1.5 seconds per item\n",
        "\n",
        "#First get a list of all the users. Email and name will be extracted based on account id later\n",
        "users = []\n",
        "for i in range(1,10):\n",
        "    usr = json.loads(requests.get(BASE_URL + '/account/institution/accounts?page_size=1000&page={}'.format(i), headers=api_call_headers).content)\n",
        "    users.extend(usr)\n",
        "\n",
        "#Then gather and format each record:\n",
        "full_records = []\n",
        "for item in published_records:\n",
        "    s=requests.get(BASE_URL + '/account/articles/' + str(item['id']), headers=api_call_headers)\n",
        "    metadata=json.loads(s.text)\n",
        "    counter = 0\n",
        "    author_list = \"\"\n",
        "    author_count = len(metadata['authors'])\n",
        "    for name in metadata['authors']: #Format author list to be readable\n",
        "        if counter == 0:\n",
        "            author_list = author_list + name['full_name'] + ' (ORCID: ' + name['orcid_id'] + ')'\n",
        "            counter += 1\n",
        "        elif counter < author_count:\n",
        "            author_list = author_list + ' | ' + name['full_name'] + ' (ORCID: ' + name['orcid_id'] + ')'\n",
        "            counter += 1\n",
        "    metadata['author_readable'] = author_list\n",
        "\n",
        "    for person in users:\n",
        "        if person['id'] == metadata['account_id']:\n",
        "            metadata['record_owner_name'] = person['first_name'] + ' ' + person['last_name'] #add in user name\n",
        "            metadata['owner_email'] = person['email'] #add user email\n",
        "\n",
        "    full_records.append(metadata)\n",
        "\n",
        "print('Full metadata for',len(full_records),'records retrieved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2149a183",
      "metadata": {
        "id": "2149a183"
      },
      "outputs": [],
      "source": [
        "#Create a dataframe from the JSON formatted data\n",
        "df = pd.DataFrame(full_records)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "developed-valentine",
      "metadata": {
        "id": "developed-valentine"
      },
      "source": [
        "## Format the spreadsheet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "universal-recipient",
      "metadata": {
        "id": "universal-recipient"
      },
      "source": [
        "### Split out the dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thick-preliminary",
      "metadata": {
        "id": "thick-preliminary"
      },
      "outputs": [],
      "source": [
        "#The dates are all contained within one column called 'timeline'. Flatten that column and associate the values\n",
        "#with the proper article id in a new dataframe\n",
        "\n",
        "temp_date_list = []\n",
        "\n",
        "for item in full_records:\n",
        "    dateitem = item['timeline']\n",
        "    dateitem['id'] = item['id']\n",
        "    temp_date_list.append(dateitem)\n",
        "\n",
        "df_dates = pd.json_normalize(\n",
        "    temp_date_list\n",
        ")\n",
        "\n",
        "#Merge the dataframes\n",
        "df_formatted = df.merge(df_dates, how='outer', on='id')\n",
        "\n",
        "print(\"Dates split out and merged\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "excited-penalty",
      "metadata": {
        "id": "excited-penalty"
      },
      "source": [
        "### Add Group names\n",
        "This retrieves a list of Groups and then formats the dataframe so that each group has id of its parent Group. The top level group has itself as the parent. The group names are then added to the main dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bored-genius",
      "metadata": {
        "id": "bored-genius"
      },
      "outputs": [],
      "source": [
        "#Get list of groups.\n",
        "s=requests.get(BASE_URL + '/account/institution/groups', headers=api_call_headers)\n",
        "groups=json.loads(s.text)\n",
        "\n",
        "#Create a dataframe of groups\n",
        "df_groups = pd.json_normalize(groups)\n",
        "\n",
        "df_groups_parent = df_groups[['id','name']] #Create reference dataframe\n",
        "df_groups = df_groups.rename(columns={'id': 'group_id','name': 'group_name'}) #Rename id col in main dataframe\n",
        "df_groups_parent = df_groups_parent.rename(columns={'name': 'parent_group_name'}) #Rename name col in reference dataframe\n",
        "\n",
        "df_groups = df_groups.sort_values(by=['parent_id'])\n",
        "top_group_id = df_groups.iloc[0]['group_id'] #Store the group id for top group\n",
        "\n",
        "df_groups.loc[df_groups['parent_id'] == 0, 'parent_id'] = top_group_id #For top level group, replace the zero value parent id with top level group id\n",
        "\n",
        "df_groups = df_groups.merge(df_groups_parent, how='inner',left_on=['parent_id'], right_on=['id']) #Add parent group name\n",
        "\n",
        "df_groups = df_groups[['group_id','group_name','parent_group_name']] #Pare down to needed columns\n",
        "\n",
        "\n",
        "#Merge the dataframes\n",
        "df_formatted = df_formatted.merge(df_groups, how='inner', on='group_id') #If you use 'outer' it will include a blank record for each group with no records\n",
        "\n",
        "print(\"Names for\",len(df_groups),\"different groups were added to the metadata records\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "inclusive-nation",
      "metadata": {
        "id": "inclusive-nation"
      },
      "source": [
        "### Split out custom fields\n",
        "This creates new columns for each custom field.\n",
        "\n",
        "If different groups have different custom metadata, check the output carefully to make sure things mapped properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alleged-cartoon",
      "metadata": {
        "id": "alleged-cartoon"
      },
      "outputs": [],
      "source": [
        "#The custom fields are all contained within one column called 'custom_fields'. Flatten that column and associate the values\n",
        "#with the proper article id in a new dataframe\n",
        "custom = pd.json_normalize(\n",
        "    full_records,\n",
        "    record_path =['custom_fields'],\n",
        "    meta=['id']\n",
        ")\n",
        "#This reshapes the data so that metadata field names are columns and each row is an id.\n",
        "custom = custom.pivot(index=\"id\", columns=\"name\", values=\"value\")\n",
        "\n",
        "#Merge the dataframes so that all the custom fields are visible along with all the other metadata\n",
        "df_formatted = df_formatted.merge(custom, how='outer', on='id') #Outer merge keeps records that have no custom metadata.\n",
        "\n",
        "print(\"Custom fields split out and merged\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "local-garden",
      "metadata": {
        "id": "local-garden"
      },
      "source": [
        "# If running this in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "legislative-intent",
      "metadata": {
        "id": "legislative-intent"
      },
      "source": [
        "## Save the Spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "convenient-transmission",
      "metadata": {
        "id": "convenient-transmission"
      },
      "outputs": [],
      "source": [
        "#When you run this cell it will ask you to authenticate so that you can create files to download\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tested-history",
      "metadata": {
        "id": "tested-history"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "df_formatted.to_csv('all-metadata-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8') #create the CSV\n",
        "files.download('all-metadata-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv') #download to your computer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "split-frontier",
      "metadata": {
        "id": "split-frontier"
      },
      "source": [
        "# If you are running this on your own system\n",
        "That is you downloaded the Jupyter Notebook file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generic-adoption",
      "metadata": {
        "id": "generic-adoption"
      },
      "source": [
        "## Save the spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "robust-directory",
      "metadata": {
        "id": "robust-directory"
      },
      "outputs": [],
      "source": [
        "#Save a CSV file of all the metadata. Change the file name if necessary to match dates.\n",
        "save_file = df_formatted.to_csv('all-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.csv',encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "composite-piano",
      "metadata": {
        "id": "composite-piano"
      },
      "outputs": [],
      "source": [
        "#Or save an Excel file of all the metadata. Change the file name if necessary to match dates.\n",
        "save_file = df_formatted.to_excel('all-records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "manual-leadership",
      "metadata": {
        "id": "manual-leadership"
      },
      "source": [
        "## Optional: Save the json formatted metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adverse-billion",
      "metadata": {
        "id": "adverse-billion"
      },
      "outputs": [],
      "source": [
        "#OPTIONAL: save the json. Change the file name to represent the list of ids you used.\n",
        "with open('full_records-'+str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))+'.json', 'w') as f:\n",
        "    json.dump(full_records, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
